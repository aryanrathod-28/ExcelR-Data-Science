{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721756ca-3fe5-4c0c-b3ec-14d65446c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Evaluation:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.60      0.83      0.70        18\n",
      "           comp.graphics       0.72      0.72      0.72        18\n",
      " comp.os.ms-windows.misc       0.75      0.95      0.84        22\n",
      "comp.sys.ibm.pc.hardware       0.72      0.84      0.78        25\n",
      "   comp.sys.mac.hardware       0.88      0.67      0.76        21\n",
      "          comp.windows.x       1.00      0.24      0.39        25\n",
      "            misc.forsale       0.82      0.78      0.80        18\n",
      "               rec.autos       0.81      0.94      0.87        18\n",
      "         rec.motorcycles       0.82      0.88      0.85        16\n",
      "      rec.sport.baseball       0.83      0.83      0.83        18\n",
      "        rec.sport.hockey       0.62      1.00      0.77        15\n",
      "               sci.crypt       0.66      1.00      0.79        19\n",
      "         sci.electronics       0.75      0.56      0.64        16\n",
      "                 sci.med       0.88      0.88      0.88        17\n",
      "               sci.space       1.00      0.90      0.95        21\n",
      "  soc.religion.christian       0.96      1.00      0.98        23\n",
      "      talk.politics.guns       0.91      0.75      0.82        28\n",
      "   talk.politics.mideast       0.95      0.95      0.95        20\n",
      "      talk.politics.misc       0.62      0.83      0.71        18\n",
      "      talk.religion.misc       0.77      0.42      0.54        24\n",
      "\n",
      "                accuracy                           0.79       400\n",
      "               macro avg       0.80      0.80      0.78       400\n",
      "            weighted avg       0.81      0.79      0.77       400\n",
      "\n",
      "[[15  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2]\n",
      " [ 0 13  0  1  0  0  1  0  0  1  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 21  0  0  0  0  1  0  0  1  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  2 14  0  1  0  0  0  1  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  2  6  2  0  6  0  0  2  1  1  4  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0 14  3  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 17  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0 14  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 15  3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  2  1  0  0  1  0  0  1  0  9  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  1  0  0  0 15  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  1  0  0  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0 21  0  5  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0 15  1]\n",
      " [10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  3 10]]\n",
      "\n",
      "Sentiment Distribution Across Categories:\n",
      "Sentiment_Label           Negative  Neutral  Positive\n",
      "Labels                                               \n",
      "alt.atheism                   21.0      NaN      79.0\n",
      "comp.graphics                 24.0      NaN      76.0\n",
      "comp.os.ms-windows.misc       19.0      NaN      81.0\n",
      "comp.sys.ibm.pc.hardware      16.0      NaN      84.0\n",
      "comp.sys.mac.hardware         19.0      NaN      81.0\n",
      "comp.windows.x                26.0      NaN      74.0\n",
      "misc.forsale                  19.0      NaN      81.0\n",
      "rec.autos                     17.0      NaN      83.0\n",
      "rec.motorcycles               22.0      NaN      78.0\n",
      "rec.sport.baseball            26.0      NaN      74.0\n",
      "rec.sport.hockey              32.0      NaN      68.0\n",
      "sci.crypt                     17.0      NaN      83.0\n",
      "sci.electronics               24.0      NaN      76.0\n",
      "sci.med                       28.0      NaN      72.0\n",
      "sci.space                     23.0      NaN      77.0\n",
      "soc.religion.christian        18.0      NaN      82.0\n",
      "talk.politics.guns            33.0      1.0      66.0\n",
      "talk.politics.mideast         19.0      NaN      81.0\n",
      "talk.politics.misc            20.0      NaN      80.0\n",
      "talk.religion.misc            14.0      NaN      86.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "\n",
    "# Download NLTK stopwords\n",
    "download('punkt')\n",
    "download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'C:\\Users\\User\\Downloads\\blogs.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "# Convert text to lowercase and clean it\n",
    "data['Data'] = data['Data'].str.lower().str.replace('[^a-z\\\\s]', '')  # Clean text\n",
    "\n",
    "# Tokenization and removal of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['Data'] = data['Data'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))\n",
    "\n",
    "# Feature Extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['Data'])\n",
    "y = data['Labels']\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes Classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation using classification report and confusion matrix\n",
    "print(\"Naive Bayes Classifier Evaluation:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Sentiment Analysis using TextBlob\n",
    "# Sentiment polarity: Positive (> 0), Neutral (0), Negative (< 0)\n",
    "data['Sentiment'] = data['Data'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "data['Sentiment_Label'] = data['Sentiment'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
    "\n",
    "# Display sentiment distribution across categories\n",
    "print(\"\\nSentiment Distribution Across Categories:\")\n",
    "sentiment_distribution = data.groupby('Labels')['Sentiment_Label'].value_counts().unstack()\n",
    "print(sentiment_distribution)\n",
    "\n",
    "# Optional: Save results to a new CSV file for further analysis\n",
    "data.to_csv('blogs_with_sentiments.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789dac5-7355-4f00-9514-89268fa16394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
