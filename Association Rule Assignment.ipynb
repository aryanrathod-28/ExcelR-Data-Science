{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d431f7d-0207-4f50-929f-2074f61e0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "                                      itemset   support\n",
      "0                             [mineral water]  0.238368\n",
      "1                                      [eggs]  0.179709\n",
      "2                                 [spaghetti]  0.174110\n",
      "3                              [french fries]  0.170911\n",
      "4                                 [chocolate]  0.163845\n",
      "..                                        ...       ...\n",
      "252              [chocolate, milk, spaghetti]  0.010932\n",
      "253              [chocolate, eggs, spaghetti]  0.010532\n",
      "254     [mineral water, olive oil, spaghetti]  0.010265\n",
      "255        [eggs, ground beef, mineral water]  0.010132\n",
      "256  [french fries, mineral water, spaghetti]  0.010132\n",
      "\n",
      "[257 rows x 2 columns]\n",
      "\n",
      "Association Rules:\n",
      "            antecedent       consequent   support  confidence      lift\n",
      "0  (ground beef, milk)  [mineral water]  0.011065    0.503030  2.110308\n",
      "1  (eggs, ground beef)  [mineral water]  0.010132    0.506667  2.125563\n",
      "\n",
      "Analysis complete. Results saved as 'frequent_itemsets_manual.csv' and 'association_rules_manual.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "file_path = r'C:\\Users\\User\\Downloads\\Association Rules\\Association Rules\\Online retail.xlsx'  \n",
    "data = pd.read_excel(file_path, header=None)  # Assuming no header in the dataset\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Split transactions into lists\n",
    "transactions = data[0].dropna().apply(lambda x: x.split(','))\n",
    "\n",
    "# Step 3: Generate frequent itemsets\n",
    "def get_itemsets(transactions, length):\n",
    "    \"\"\"Generate all itemsets of a given length from transactions.\"\"\"\n",
    "    itemsets = []\n",
    "    for transaction in transactions:\n",
    "        itemsets.extend(combinations(sorted(set(transaction)), length))\n",
    "    return pd.Series(itemsets).value_counts()\n",
    "\n",
    "def apriori(transactions, min_support):\n",
    "    \"\"\"Generate frequent itemsets using the Apriori algorithm.\"\"\"\n",
    "    # Convert transactions to list of lists\n",
    "    transactions = transactions.tolist()\n",
    "\n",
    "    # Generate frequent itemsets\n",
    "    frequent_itemsets = []\n",
    "    k = 1\n",
    "    while True:\n",
    "        # Get itemsets of length k\n",
    "        itemsets = get_itemsets(transactions, k)\n",
    "\n",
    "        # Calculate support\n",
    "        itemsets = itemsets[itemsets / len(transactions) >= min_support]\n",
    "\n",
    "        # Stop if no itemsets meet the minimum support\n",
    "        if itemsets.empty:\n",
    "            break\n",
    "\n",
    "        # Add to frequent itemsets\n",
    "        frequent_itemsets.extend([(list(item), support / len(transactions)) for item, support in itemsets.items()])\n",
    "        k += 1\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(frequent_itemsets, columns=['itemset', 'support'])\n",
    "\n",
    "# Set the minimum support threshold\n",
    "min_support = 0.01\n",
    "frequent_itemsets = apriori(transactions, min_support)\n",
    "\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Step 4: Generate association rules\n",
    "def generate_rules(frequent_itemsets, min_confidence):\n",
    "    \"\"\"Generate association rules from frequent itemsets.\"\"\"\n",
    "    rules = []\n",
    "    for _, row in frequent_itemsets.iterrows():\n",
    "        itemset = row['itemset']\n",
    "        itemset_support = row['support']\n",
    "\n",
    "        if len(itemset) > 1:\n",
    "            # Generate all possible combinations of antecedent and consequent\n",
    "            for i in range(1, len(itemset)):\n",
    "                antecedents = list(combinations(itemset, i))\n",
    "                for antecedent in antecedents:\n",
    "                    consequent = list(set(itemset) - set(antecedent))\n",
    "                    if len(consequent) > 0:\n",
    "                        antecedent_support = frequent_itemsets.loc[\n",
    "                            frequent_itemsets['itemset'].apply(set) == set(antecedent), 'support'\n",
    "                        ].values[0]\n",
    "                        confidence = itemset_support / antecedent_support\n",
    "                        if confidence >= min_confidence:\n",
    "                            rules.append({\n",
    "                                'antecedent': antecedent,\n",
    "                                'consequent': consequent,\n",
    "                                'support': itemset_support,\n",
    "                                'confidence': confidence,\n",
    "                                'lift': confidence / frequent_itemsets.loc[\n",
    "                                    frequent_itemsets['itemset'].apply(set) == set(consequent), 'support'\n",
    "                                ].values[0]\n",
    "                            })\n",
    "    return pd.DataFrame(rules)\n",
    "\n",
    "# Set the minimum confidence threshold\n",
    "min_confidence = 0.5\n",
    "rules = generate_rules(frequent_itemsets, min_confidence)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n",
    "\n",
    "# Step 5: Analysis\n",
    "# Save results to files\n",
    "frequent_itemsets.to_csv('frequent_itemsets_manual.csv', index=False)\n",
    "rules.to_csv('association_rules_manual.csv', index=False)\n",
    "\n",
    "print(\"\\nAnalysis complete. Results saved as 'frequent_itemsets_manual.csv' and 'association_rules_manual.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd8f64-51b5-427c-9fc7-13447850f8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
